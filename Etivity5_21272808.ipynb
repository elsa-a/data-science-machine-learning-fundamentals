{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Etivity5_21272808.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5qI85rrEU58"
      },
      "source": [
        "# Etivity 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXoqTI3OEQ2s"
      },
      "source": [
        "Student ID: 21272808\n",
        "\n",
        "Student Name: Elsa Anza Martín"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBJrfaQc_STC",
        "outputId": "9f032ba4-c626-426e-e6c9-466bccad9df5"
      },
      "source": [
        "!wget http://ptrckprry.com/course/ssd/data/positive-words.txt\n",
        "filePath = \"positive-words.txt\"\n",
        "pwordsFile = open(filePath, \"r\")\n",
        "positiveWords = pwordsFile.read()\n",
        "positiveWords = positiveWords.splitlines()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-19 23:47:48--  http://ptrckprry.com/course/ssd/data/positive-words.txt\n",
            "Resolving ptrckprry.com (ptrckprry.com)... 185.199.109.153, 185.199.110.153, 185.199.108.153, ...\n",
            "Connecting to ptrckprry.com (ptrckprry.com)|185.199.109.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://ptrckprry.com/course/ssd/data/positive-words.txt [following]\n",
            "--2021-11-19 23:47:49--  https://ptrckprry.com/course/ssd/data/positive-words.txt\n",
            "Connecting to ptrckprry.com (ptrckprry.com)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20630 (20K) [text/plain]\n",
            "Saving to: ‘positive-words.txt.1’\n",
            "\n",
            "positive-words.txt. 100%[===================>]  20.15K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-11-19 23:47:49 (14.9 MB/s) - ‘positive-words.txt.1’ saved [20630/20630]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SgL6thQEO1P",
        "outputId": "73868d80-7bdf-4c19-b84d-be604a53fc61"
      },
      "source": [
        "positiveWords[100:120]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['affirmation',\n",
              " 'affirmative',\n",
              " 'affluence',\n",
              " 'affluent',\n",
              " 'afford',\n",
              " 'affordable',\n",
              " 'affordably',\n",
              " 'afordable',\n",
              " 'agile',\n",
              " 'agilely',\n",
              " 'agility',\n",
              " 'agreeable',\n",
              " 'agreeableness',\n",
              " 'agreeably',\n",
              " 'all-around',\n",
              " 'alluring',\n",
              " 'alluringly',\n",
              " 'altruistic',\n",
              " 'altruistically',\n",
              " 'amaze']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDZLjfWQEP4u",
        "outputId": "05185aed-6ba7-4b28-a99e-823d833dd318"
      },
      "source": [
        "!wget http://ptrckprry.com/course/ssd/data/negative-words.txt\n",
        "filePath = \"negative-words.txt\"\n",
        "nwordsFile = open(filePath, \"r\", encoding = \"ISO-8859-1\")\n",
        "negativeWords = nwordsFile.read()\n",
        "negativeWords = negativeWords.splitlines()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-19 23:47:49--  http://ptrckprry.com/course/ssd/data/negative-words.txt\n",
            "Resolving ptrckprry.com (ptrckprry.com)... 185.199.109.153, 185.199.110.153, 185.199.108.153, ...\n",
            "Connecting to ptrckprry.com (ptrckprry.com)|185.199.109.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://ptrckprry.com/course/ssd/data/negative-words.txt [following]\n",
            "--2021-11-19 23:47:49--  https://ptrckprry.com/course/ssd/data/negative-words.txt\n",
            "Connecting to ptrckprry.com (ptrckprry.com)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46299 (45K) [text/plain]\n",
            "Saving to: ‘negative-words.txt.1’\n",
            "\n",
            "negative-words.txt. 100%[===================>]  45.21K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-11-19 23:47:50 (3.48 MB/s) - ‘negative-words.txt.1’ saved [46299/46299]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXEMEMfyE11e",
        "outputId": "b7a907d4-6641-40b9-c2fd-a39fa411cef6"
      },
      "source": [
        "negativeWords[0:10]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;',\n",
              " '; ',\n",
              " '; Opinion Lexicon: Negative',\n",
              " ';',\n",
              " '; This file contains a list of NEGATIVE opinion words (or sentiment words).',\n",
              " ';',\n",
              " '; This file and the papers can all be downloaded from ',\n",
              " ';    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html',\n",
              " ';',\n",
              " '; If you use this list, please cite one of the following two papers:']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKSkhNjTN1bm"
      },
      "source": [
        "for i in range(35):\n",
        "  negativeWords.pop(0)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMkXr_bmONFD",
        "outputId": "65208224-6eab-462b-99e6-1ff3e5b95058"
      },
      "source": [
        "negativeWords[0:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2-faced',\n",
              " '2-faces',\n",
              " 'abnormal',\n",
              " 'abolish',\n",
              " 'abominable',\n",
              " 'abominably',\n",
              " 'abominate',\n",
              " 'abomination',\n",
              " 'abort',\n",
              " 'aborted']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ6XQpcZFOWs"
      },
      "source": [
        "Count the number of positive and negative words that appear in a given text.\n",
        "If the number of positive word appearances is greater than the number of negative word appearances, the system returns a positive sentiment and vice versa. If the numbers are even, the system will return a neutral sentiment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnBuKu7ZFE2w"
      },
      "source": [
        "def sentAnalyser(text):\n",
        "  text = text.split()\n",
        "  neg_count = 0\n",
        "  pos_count = 0\n",
        "  for i in text:\n",
        "    for j in negativeWords:\n",
        "      if i == j:\n",
        "        neg_count = neg_count+1\n",
        "\n",
        "    for k in positiveWords:\n",
        "      if i == k:\n",
        "        pos_count = pos_count+1\n",
        "\n",
        "  if pos_count > neg_count:\n",
        "    print(\"Text is positive\")\n",
        "    confidence = pos_count/len(text)\n",
        "  elif pos_count == neg_count:\n",
        "    print(\"Text is neutral\")\n",
        "    confidence = neg_count/len(text)\n",
        "    \n",
        "  else: \n",
        "    print(\"Text is negative\")\n",
        "    confidence = neg_count/len(text)\n",
        "  \n",
        "  print (\"confidence is:\", confidence)\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rwYPOYLQN-S",
        "outputId": "476a5b0b-7f75-460f-aaee-25e59acf1011"
      },
      "source": [
        "sentAnalyser(\"NLP is cool\")\n",
        "sentAnalyser(\"NLP is cool and useful\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text is positive\n",
            "confidence is: 0.3333333333333333\n",
            "Text is positive\n",
            "confidence is: 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyNTyCkCYB4g",
        "outputId": "4eb168a1-cf0b-46a9-8573-cd6ae9d3137a"
      },
      "source": [
        "\n",
        "sentAnalyser(\"NLP is hard\")\n",
        "sentAnalyser(\"NLP is hard and useless\")\n",
        "sentAnalyser(\"NLP stands for Natural Language Processing\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text is negative\n",
            "confidence is: 0.3333333333333333\n",
            "Text is negative\n",
            "confidence is: 0.4\n",
            "Text is neutral\n",
            "confidence is: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig0yK-SFa3S3"
      },
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89u-pUS9a_sY"
      },
      "source": [
        "Write a NaiveBayes function which takes the sample training and testing documents shown in the table below as input, and uses the Naive Bayes algorithm to classify the test documents.\n",
        "\n",
        "Hint1: do not forget to normalise (case-fold) your train & test docs.\n",
        "\n",
        "Hint2: Python Dictionaries are suitable data structures for storing BOWs (Bag Of Words)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA409S7Catgw"
      },
      "source": [
        "trainingSet = [('London is the Capital of GB','GB'),('Oxford is a city in GB','GB'),('Dublin is the capital of Ireland','IE'),('Limerick is a city in Ireland','IE')]\n",
        "testSet = [('University of Limerick','?'),('University College Dublin','?'),('Imperial College London','?'),('Ireland & GB','?')]\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJfDH9aoHvmj"
      },
      "source": [
        "def priors(a):\n",
        "  dict_classes = {}\n",
        "  list_classes = []\n",
        "  total_classes = len(a)\n",
        "  for i in range(len(a)):\n",
        "    if a[i][1] in dict_classes:\n",
        "      dict_classes[a[i][1]] = dict_classes[a[i][1]] + 1\n",
        "    else:\n",
        "      dict_classes[a[i][1]] = 1\n",
        "      list_classes.append(a[i][1])\n",
        "\n",
        "  priors = []\n",
        "  for i in range(len(list_classes)): \n",
        "    p = dict_classes[list_classes[1]]/total_classes\n",
        "    priors.append(p)\n",
        "  \n",
        "  return dict_classes, list_classes, priors"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkf0wr5jyrrc"
      },
      "source": [
        "#function that creates a dict with counts for each word regarding their class\n",
        "\n",
        "def BOW(corpus):\n",
        "#  classes = []\n",
        "  a = corpus[0][1]\n",
        "  b = corpus[2][1]\n",
        "  dict1 = {}\n",
        "  dict2 = {}\n",
        "  a = corpus[0][1]\n",
        "\n",
        "  for i in range(len(corpus)):\n",
        "    if corpus[i][1] == a:\n",
        "      vocabularylist = corpus[i][0].lower().split()\n",
        "      for i in vocabularylist:\n",
        "#        print (i, end=' ')\n",
        "        if i in dict1:\n",
        "          dict1[i] = dict1[i] + 1\n",
        "#          print(\"\\t(already here)\\n\")\n",
        "        else:\n",
        "#          print(\"\\t(new)\\n\")\n",
        "          dict1[i] = 1\n",
        "          \n",
        "    else:\n",
        "      vocabularylist2 = corpus[i][0].lower().split()\n",
        "      for i in vocabularylist2:\n",
        "#        print (i, end=' ')\n",
        "        if i in dict2:\n",
        "          dict2[i] = dict2[i] + 1\n",
        "#          print(\"\\t(already here)\\n\")\n",
        "        else:\n",
        "#          print(\"\\t(new)\\n\")\n",
        "          dict2[i] = 1\n",
        "\n",
        "  v = []\n",
        "  for i in dict1:\n",
        "    if i in v:\n",
        "      pass\n",
        "    else:\n",
        "      v.append(i)\n",
        "    \n",
        "  for i in dict2:\n",
        "    if i in v:\n",
        "      pass\n",
        "    else:\n",
        "      v.append(i)\n",
        "  return dict1, dict2, v"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb3R6dd2jTF4"
      },
      "source": [
        "#counting dictionaries \n",
        "\n",
        "def count(a):\n",
        "\n",
        "  c = 0\n",
        "  for i in a:\n",
        "    c = c + a[i]\n",
        "  return c"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7FCHuDhayOO",
        "outputId": "2a2c417a-8665-428f-a3f3-ef2c9e24b4bb"
      },
      "source": [
        "testSet"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('University of Limerick', '?'),\n",
              " ('University College Dublin', '?'),\n",
              " ('Imperial College London', '?'),\n",
              " ('Ireland & GB', '?')]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moae2u-3RVsc"
      },
      "source": [
        "def NBC(train, test):\n",
        "  bow1, bow2, v = BOW(train)\n",
        "  priors\n",
        "  print (\"Document: \", test)\n",
        "  test = test.lower().split()\n",
        "  words = []\n",
        "\n",
        "  print(\"\\nConditional probabilities for class GB\")\n",
        "  #class1\n",
        "\n",
        "  p1 = 1\n",
        "\n",
        "  for i in test:\n",
        "    if i in bow1:\n",
        "      count_w = bow1[i]\n",
        "      cp1 = (count_w+1 )/(count(bow1)+len(v))\n",
        "      cp1 = round(cp1, 2)\n",
        "      print (cp1)\n",
        "      p1 = p1 *cp1\n",
        "\n",
        "    else:\n",
        "      cp1 = (0+1 )/(count(bow1)+len(v))\n",
        "      cp1 = round(cp1, 2)\n",
        "      print (cp1)\n",
        "      p1 = p1 *cp1\n",
        "  print(\"\\nConditional probabilities for class IE\")\n",
        "  #class2\n",
        "  p2 = 1\n",
        "  for i in test:\n",
        "    if i in bow2:\n",
        "      count_w = bow2[i]\n",
        "      cp2 =( count_w+1 )/(count(bow2)+len(v))\n",
        "      cp2 = round(cp2, 2)\n",
        "      print (cp2)\n",
        "      p2 = p2 *cp2\n",
        "      \n",
        "\n",
        "    else:\n",
        "      cp2 =(0+1 )/(count(bow2)+len(v))\n",
        "      cp2 = round(cp2, 2)\n",
        "      print (cp2)\n",
        "      p2 = p2 *cp2\n",
        "    \n",
        "  a, b, prior = priors(train)\n",
        "  priorGB = prior[0]\n",
        "  priorIE = prior[1]\n",
        "\n",
        "  print(\"PGB\", p1)\n",
        "  print(\"PIE\", p2)\n",
        "  pGB = priorGB * p1\n",
        "\n",
        "\n",
        "  pIE = priorIE * p2\n",
        "  \n",
        "  if pGB > pIE:\n",
        "    print(\"\\nInferred class is GB\")\n",
        "  if pGB < pIE:\n",
        "    print(\"\\nInferred class is IE\")\n",
        "  else:\n",
        "    print(\"not enough confidence to infer class\")\n",
        "\n",
        "  pGB = f\"{pGB:.10f}\"  \n",
        "  pIE = f\"{pIE:.10f}\"\n",
        "  print (\"\\nP(d1|GB):\", pGB)\n",
        "  print (\"\\nP(d1|IE):\", pIE)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE0lpEh9mCx6"
      },
      "source": [
        "# Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "213uHvWnaq02",
        "outputId": "efd7377a-810f-4b31-bfd4-a5fba1d4a78b"
      },
      "source": [
        "NBC(trainingSet, testSet[0][0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document:  University of Limerick\n",
            "\n",
            "Conditional probabilities for class GB\n",
            "0.04\n",
            "0.08\n",
            "0.04\n",
            "\n",
            "Conditional probabilities for class IE\n",
            "0.04\n",
            "0.08\n",
            "0.08\n",
            "PGB 0.00012800000000000002\n",
            "PIE 0.00025600000000000004\n",
            "\n",
            "Inferred class is IE\n",
            "\n",
            "P(d1|GB): 0.0000640000\n",
            "\n",
            "P(d1|IE): 0.0001280000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK0pbS_lWL1z",
        "outputId": "896e8e07-b4d5-40d0-e3f2-727e1e8f5a23"
      },
      "source": [
        "NBC(trainingSet, testSet[1][0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document:  University College Dublin\n",
            "\n",
            "Conditional probabilities for class GB\n",
            "0.04\n",
            "0.04\n",
            "0.04\n",
            "\n",
            "Conditional probabilities for class IE\n",
            "0.04\n",
            "0.04\n",
            "0.08\n",
            "PGB 6.400000000000001e-05\n",
            "PIE 0.00012800000000000002\n",
            "\n",
            "Inferred class is IE\n",
            "\n",
            "P(d1|GB): 0.0000320000\n",
            "\n",
            "P(d1|IE): 0.0000640000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7-hgtTul3eJ",
        "outputId": "03e9dc1d-6eec-4092-d7bc-77062f3d92a7"
      },
      "source": [
        "NBC(trainingSet, testSet[2][0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document:  Imperial College London\n",
            "\n",
            "Conditional probabilities for class GB\n",
            "0.04\n",
            "0.04\n",
            "0.08\n",
            "\n",
            "Conditional probabilities for class IE\n",
            "0.04\n",
            "0.04\n",
            "0.04\n",
            "PGB 0.00012800000000000002\n",
            "PIE 6.400000000000001e-05\n",
            "\n",
            "Inferred class is GB\n",
            "not enough confidence to infer class\n",
            "\n",
            "P(d1|GB): 0.0000640000\n",
            "\n",
            "P(d1|IE): 0.0000320000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWnioAvLl5ur",
        "outputId": "89025f7a-25df-4d0e-99f3-1b22f7b6bc79"
      },
      "source": [
        "NBC(trainingSet, testSet[3][0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document:  Ireland & GB\n",
            "\n",
            "Conditional probabilities for class GB\n",
            "0.04\n",
            "0.04\n",
            "0.12\n",
            "\n",
            "Conditional probabilities for class IE\n",
            "0.12\n",
            "0.04\n",
            "0.04\n",
            "PGB 0.000192\n",
            "PIE 0.00019199999999999998\n",
            "\n",
            "Inferred class is GB\n",
            "not enough confidence to infer class\n",
            "\n",
            "P(d1|GB): 0.0000960000\n",
            "\n",
            "P(d1|IE): 0.0000960000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFUHHqpLmBLD"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-OVTsN-sG5H"
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": []
    }
  ]
}